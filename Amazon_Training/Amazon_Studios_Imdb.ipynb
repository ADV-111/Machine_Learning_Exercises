{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aggregate the various elements of managing data, consider the following analogy.\n",
    "\n",
    "Eyes are like little digital cameras that have been optimized over millions of evolutionary years to be the means through which we consume the world.\n",
    "\n",
    "We can focus our eyse to direct our brain power where it will be most useful and, over time, we merge the abstract arrangemnet of waht we see into patterns that help us make sense of it all.\n",
    "\n",
    "A mouth, a nose, and a pair of eyes make a face. Four wheels, some doors, and a steering wheel all tethered to a metal frame make a car. Tall buildings, roadways, and numbers of people make a city. These things ring true, even in abstract form, because over the years the visual system has become a pattern finding machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Notebook, and Cleaning and Visualizing Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the eyes of a child the world is a conglomerate of textures, gradients, heights, shadows, contrasts, and depths. A baby might stumble across a copy the Wall Street Journal and discard any attempt to parse the written content covering interantional fiancne regulations because tha is irrelvent to her world model. However, she will catalog the features of the newspaper as \"big\", \"fun to grab\", and \"not tasty\"\n",
    "\n",
    "-------------\n",
    "\n",
    "Sifting through all of this data to find apatterns and associate meaning takes time, but to fidn a pattern is to find a solution.\n",
    "\n",
    "-------------\n",
    "\n",
    "To do this susccessfully, both as a child and in machine learning, you need to collect as much data as possible and then reduce the amount of fragmented data. You form a hypthesis and say to yourself, \"I think I'll need these features\" so you gather that data, conduct your experiment, get your results and adjust your features accordingly - diciding what data helps your model and waht is a distractor. And you do this repeatedly. WIth regard to machine learning, these processes are formally referred to as cleaning and visualizing your data.\n",
    "\n",
    "Let's get started with an introduction to the notebook we'll be using, and then dive right into the processes of cleaning and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
